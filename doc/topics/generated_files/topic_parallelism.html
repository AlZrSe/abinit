<html>
<head><title>parallelism </title>
<link rel=stylesheet type="text/css" href="../formabinit.css">
</head>
<body bgcolor="#ffffff">

<hr>
<a name="top"></a>

<h1>Parallelism</h1>
<h3>This file gives hints on how to set parameters for a parallel calculation with the ABINIT package.
<hr>

<h5>Copyright (C) 2016-2017 ABINIT group (FJ)
<script type="text/javascript" src="../../js_files/copyright.js"> </script>
</h5>

<script type="text/javascript" src="../../js_files/list_internal_links_for_generated_files.js"> </script>

 <h3><b>Table of content: </b></h3> 
 <ul> <li><a href="topic_parallelism.html#1">1</a>. Introduction.<li><a href="topic_parallelism.html#2">2</a>. Related tutorials.<li><a href="topic_parallelism.html#3">3</a>. Related input variables.<li><a href="topic_parallelism.html#4">4</a>. Selected input files.</ul>

&nbsp; 
<HR ALIGN=left> 
<a name="1">&nbsp;</a>
<h3><b>1. Introduction.</b></h3>


<li>
For ground-state calculations, 
the code has been parallelized (MPI-based parallelism)
on the k-points, on the spins, on the spinor components, on the bands,
and on the FFT grid and plane wave coefficients.
For the k-point and spin parallelisations (using MPI), the communication
load is generally very small. This allows it to be used on a cluster of workstations.
However, the number of nodes that can be used in parallel might
be small, and depends strongly on the physics of the problem.
A combined FFT / band parallelisation (LOBPCG)is available, and has shown
very large speed up (>1000) on powerful computers with a large number of processors
and high-speed interconnect. The combination of FFT / band / k point and spin
parallelism is also available, and quite efficient for such computers.
Available for norm-conserving as well as PAW cases.
Automatic determination of the best combination of parallelism levels is available.
Use of MPIIO is mandatory for the largest speed ups to be observed.
</li>
<li>
Chebyshev filtering (Chebfi) is a method to solve the linear
eigenvalue problem, and can be used as a SCF solver in Abinit. It is
implemented in Abinit. The design goal is for Chebfi to replace LOBPCG as the solver of
choice for large-scale computations in Abinit. By performing less
orthogonalizations and diagonalizations than LOBPCG, scaling to higher
processor counts is possible. A manual to use Chebfi is available <a href="../documents/howto_chebfi.pdf">here</a>. 
</li>
<li>
For ground-state calculations, with a set of images (e.g. nudged elastic band method,
the string method, the path-integral molecular dynamics, the genetic algorithm), MPI-based parallelism is used.
The work load for the different images has been distributed, and this parallelism can be 
combined with the parallelism described in point hereabove, leading to speed-up beyond 5000.
</li>
<li>
For ground-state calculations, GPU can be used. This is based on CUDA+MAGMA.
</li>
<br>
<li>
For ground-state calculations, the wavelet part of ABINIT (BigDFT) is also very well parallelized :
MPI band parallelism, combined with GPUs.
</li>
<li>
For response calculations, the code has been parallelized (MPI-based parallelism)
on k-points, spins, bands, as well as on perturbations.
For the k-points, spins and bands parallelisation,
the communication load is rather
small also, and, unlike for the GS calculations, the number
of nodes that can be used in parallel will be large,
nearly independently of the physics of the problem.
Parallelism on perturbations is very similar to the parallelism on images in the ground state case (so, very efficient),
although the load balancing problem for perturbations with different number of k points is not adressed at present.
Use of MPIIO is mandatory for the largest speed ups to be observed.
</li>
<br>
<li>
GW calculations are MPI-parallelized over k-points.
They are also parallelized over transitions (valence to conduction band pairs), but the two parallelisation
cannot be used currently at present.
The transition parallelism has been show to allow speed ups as large as 300.
</li>
<br>
<li>
Ground state, response function, and GW parallel calculations 
can be done also by using OpenMP parallelism, even combined with MPI parallelism. 
</li>
<p>


&nbsp; 
<HR ALIGN=left> 
<a name="2">&nbsp;</a>
<h3><b>2. Related tutorials.</b></h3>


<li><a href="../../tutorial/generated_files/lesson_basepar.html">An introduction on ABINIT in
Parallel</a> should be read before going to the next lessons about
parallelism. One simple example of parallelism in ABINIT will be
shown.</li>
<li><a href="../../tutorial/generated_files/lesson_paral_gspw.html">Parallelism for ground-state
calculations, with plane waves</a> presents the combined k-point (K),
plane-wave (G), band (B), spin/spinor parallelism of ABINIT (so, the
"KGB" parallelism), for the computation of total energy, density, and
ground state properties </li>
<li><a href="../../tutorial/generated_files/lesson_paral_moldyn.html">Parallelism for molecular
dynamics calculations</a></li>
<li><a href="../../tutorial/generated_files/lesson_paral_string.html">Parallelism based on "images",
e.g. for the determination of transitions paths (string method)</a>,
that can be activated on top of the "KGB" parallelism for force
calculations.</li>
<li><a href="../../tutorial/generated_files/lesson_paral_gswvl.html">Parallelism for ground-state
calculations, with wavelets</a> presents the parallelism of ABINIT,
when wavelets are used as a basis function instead of planewaves, for
the computation of total energy, density, and ground state properties</li>
<li><a href="../../tutorial/generated_files/lesson_paral_dfpt.html">Parallelism of response-function
calculations</a> - you need to be familiarized with the calculation of
linear-response properties within ABINIT, see the tutorial <a
href="../../tutorial/generated_files/lesson_rf1.html"> Response-Function 1 (RF1)</a></li>
<li><a href="../../tutorial/generated_files/lesson_paral_mbt.html">Parallelism of Many-Body
Perturbation calculations (GW)</a> allows to speed up the calculation of
accurate electronic structures (quasi-particle band structure,
including many-body effects).</li>

&nbsp; 
<HR ALIGN=left> 
<a name="3">&nbsp;</a>
<h3><b>3. Related input variables.</b></h3>


<p>Basic input variables:<p>... <a href="../../input_variables/generated_files/varpar.html#autoparal">autoparal</a>   [AUTOmatisation of the PARALlelism]<br>
... <a href="../../input_variables/generated_files/varpar.html#paral_atom">paral_atom</a>   [activate PARALelization over (paw) ATOMic sites]<br>
... <a href="../../input_variables/generated_files/varpar.html#paral_kgb">paral_kgb</a>   [activate PARALelization over K-point, G-vectors and Bands]<br>
... <a href="../../input_variables/generated_files/varpar.html#paral_rf">paral_rf</a>   [activate PARALlelization over Response Function perturbations]<br>
<p>Useful input variables:<p>... <a href="../../input_variables/generated_files/varpar.html#bandpp">bandpp</a>   [BAND Per Processor]<br>
... <a href="../../input_variables/generated_files/varpar.html#gwpara">gwpara</a>   [GW PARAllelization level]<br>
... <a href="../../input_variables/generated_files/varpar.html#max_ncpus">max_ncpus</a>   [MAXimum Number of CPUS]<br>
... <a href="../../input_variables/generated_files/varpar.html#npband">npband</a>   [Number of Processors at the BAND level]<br>
... <a href="../../input_variables/generated_files/varpar.html#npfft">npfft</a>   [Number of Processors at the FFT level]<br>
... <a href="../../input_variables/generated_files/varpar.html#nphf">nphf</a>   [Number of Processors for (Hartree)-Fock exact exchange]<br>
... <a href="../../input_variables/generated_files/varpar.html#npimage">npimage</a>   [Number of Processors at the IMAGE level]<br>
... <a href="../../input_variables/generated_files/varpar.html#npkpt">npkpt</a>   [Number of Processors at the K-Point Level]<br>
... <a href="../../input_variables/generated_files/varpar.html#nppert">nppert</a>   [Number of Processors at the PERTurbation level]<br>
... <a href="../../input_variables/generated_files/varpar.html#npspinor">npspinor</a>   [Number of Processors at the SPINOR level]<br>
<p>Input variables for experts:<p>... <a href="../../input_variables/generated_files/varpar.html#gpu_devices">gpu_devices</a>   [GPU: choice of DEVICES on one node]<br>
... <a href="../../input_variables/generated_files/varpar.html#gpu_linalg_limit">gpu_linalg_limit</a>   [GPU (Cuda): LINear ALGebra LIMIT]<br>
... <a href="../../input_variables/generated_files/vardev.html#iomode">iomode</a>   [Input-Output MODE]<br>
... <a href="../../input_variables/generated_files/varpar.html#localrdwf">localrdwf</a>   [LOCAL ReaD WaveFunctions]<br>
... <a href="../../input_variables/generated_files/varpar.html#np_slk">np_slk</a>   [Number of mpi Processors used for ScaLapacK calls]<br>
... <a href="../../input_variables/generated_files/varpar.html#pw_unbal_thresh">pw_unbal_thresh</a>   [Plane Wave UNBALancing: THRESHold for balancing procedure]<br>
... <a href="../../input_variables/generated_files/vardev.html#use_gemm_nonlop">use_gemm_nonlop</a>   [USE the GEMM routine for the application of the NON-Local OPerator]<br>
... <a href="../../input_variables/generated_files/varpar.html#use_gpu_cuda">use_gpu_cuda</a>   [activate USE of GPU accelerators with CUDA (nvidia)]<br>


&nbsp; 
<HR ALIGN=left> 
<a name="4">&nbsp;</a>
<h3><b>4. Selected input files.</b></h3>


The user can find some related example input files in the ABINIT package in the directory /tests, or on the Web:
<p> tests/paral/Input: <a href="../../tests/paral/Input/t08.in">t08.in</a> 
<a href="../../tests/paral/Input/t21.in">t21.in</a> 
<a href="../../tests/paral/Input/t22.in">t22.in</a> 
<a href="../../tests/paral/Input/t23.in">t23.in</a> 
<a href="../../tests/paral/Input/t24.in">t24.in</a> 
<a href="../../tests/paral/Input/t25.in">t25.in</a> 
<a href="../../tests/paral/Input/t26.in">t26.in</a> 
<a href="../../tests/paral/Input/t29.in">t29.in</a> 
<a href="../../tests/paral/Input/t30.in">t30.in</a> 
<a href="../../tests/paral/Input/t51.in">t51.in</a> 
<br>


<script type="text/javascript" src="../../js_files/list_internal_links_for_generated_files.js"> </script>

</body>
</html>

